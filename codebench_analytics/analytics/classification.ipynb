{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbdf7181",
   "metadata": {},
   "source": [
    "# Modelos de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f65e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e2c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83378a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity</th>\n",
       "      <th>loc</th>\n",
       "      <th>lloc</th>\n",
       "      <th>sloc</th>\n",
       "      <th>comments</th>\n",
       "      <th>single_comments</th>\n",
       "      <th>multi_comments</th>\n",
       "      <th>blank_lines</th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>...</th>\n",
       "      <th>builtin_type</th>\n",
       "      <th>builtin_func</th>\n",
       "      <th>kwd_print</th>\n",
       "      <th>kwd_input</th>\n",
       "      <th>builtin_type_unique</th>\n",
       "      <th>builtin_func_unique</th>\n",
       "      <th>identifiers_unique</th>\n",
       "      <th>identifiers_max_len</th>\n",
       "      <th>identifiers_min_len</th>\n",
       "      <th>identifiers_mean_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>4.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          complexity   loc  lloc  sloc  comments  single_comments  \\\n",
       "question                                                            \n",
       "1002             1.0   6.0   6.0   6.0       0.0              0.0   \n",
       "1020             1.0   7.0   7.0   7.0       0.0              0.0   \n",
       "1023             1.0   6.0   6.0   6.0       0.0              0.0   \n",
       "1025             1.0  10.0   6.0   6.0       3.0              3.0   \n",
       "1027             1.0   6.0   4.0   4.0       0.0              0.0   \n",
       "...              ...   ...   ...   ...       ...              ...   \n",
       "3210             4.0  31.0  16.0  15.0       2.0              2.0   \n",
       "3229             1.0  13.0   7.0   8.0       3.0              2.0   \n",
       "3309             1.0   6.0   4.0   4.0       0.0              0.0   \n",
       "3583             3.0  22.0  10.0   9.0       1.0              1.0   \n",
       "3680             4.0  11.0   8.0   8.0       0.0              0.0   \n",
       "\n",
       "          multi_comments  blank_lines   h1    h2  ...  builtin_type  \\\n",
       "question                                          ...                 \n",
       "1002                 0.0          0.0  2.0   6.0  ...           2.0   \n",
       "1020                 0.0          0.0  3.0   8.0  ...           4.0   \n",
       "1023                 0.0          0.0  1.0   6.0  ...           2.0   \n",
       "1025                 0.0          1.0  2.0   6.0  ...           3.0   \n",
       "1027                 0.0          2.0  2.0   7.0  ...           1.0   \n",
       "...                  ...          ...  ...   ...  ...           ...   \n",
       "3210                 5.0          9.0  1.0   2.0  ...           8.0   \n",
       "3229                 0.0          3.0  0.0   0.0  ...           0.0   \n",
       "3309                 0.0          2.0  2.0   7.0  ...           1.0   \n",
       "3583                 7.0          5.0  5.0  10.0  ...           0.0   \n",
       "3680                 0.0          3.0  1.0   2.0  ...           4.0   \n",
       "\n",
       "          builtin_func  kwd_print  kwd_input  builtin_type_unique  \\\n",
       "question                                                            \n",
       "1002               1.0        1.0        2.0                    1   \n",
       "1020               1.0        1.0        4.0                    1   \n",
       "1023               1.0        1.0        2.0                    1   \n",
       "1025               1.0        1.0        3.0                    1   \n",
       "1027               1.0        1.0        1.0                    1   \n",
       "...                ...        ...        ...                  ...   \n",
       "3210               0.0        2.0        2.0                    3   \n",
       "3229               1.0        1.0        1.0                    0   \n",
       "3309               1.0        1.0        1.0                    1   \n",
       "3583               3.0        1.0        1.0                    0   \n",
       "3680               0.0        1.0        1.0                    2   \n",
       "\n",
       "          builtin_func_unique  identifiers_unique  identifiers_max_len  \\\n",
       "question                                                                 \n",
       "1002                        3                   6                 12.0   \n",
       "1020                        3                   6                  5.0   \n",
       "1023                        3                   6                 19.0   \n",
       "1025                        3                   5                 11.0   \n",
       "1027                        3                   2                 11.0   \n",
       "...                       ...                 ...                  ...   \n",
       "3210                        2                  11                  9.0   \n",
       "3229                        3                   9                  7.0   \n",
       "3309                        3                   2                 11.0   \n",
       "3583                        5                   6                  9.0   \n",
       "3680                        2                   7                  6.0   \n",
       "\n",
       "          identifiers_min_len  identifiers_mean_len  \n",
       "question                                             \n",
       "1002                      2.0              6.000000  \n",
       "1020                      1.0              2.166667  \n",
       "1023                      2.0              8.333333  \n",
       "1025                      1.0              5.400000  \n",
       "1027                      7.0              9.000000  \n",
       "...                       ...                   ...  \n",
       "3210                      1.0              5.181818  \n",
       "3229                      1.0              4.555556  \n",
       "3309                      5.0              8.000000  \n",
       "3583                      1.0              4.166667  \n",
       "3680                      1.0              3.428571  \n",
       "\n",
       "[395 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_vars = pd.read_csv('./code_metrics.csv', index_col='question')\n",
    "ind_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5bd9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxa_acerto</th>\n",
       "      <th>num_submissoes</th>\n",
       "      <th>taxa_aceitacao</th>\n",
       "      <th>num_testes</th>\n",
       "      <th>num_consultas</th>\n",
       "      <th>num_erros</th>\n",
       "      <th>num_erros_lgcs</th>\n",
       "      <th>num_errors_stx</th>\n",
       "      <th>num_eventos</th>\n",
       "      <th>num_eventos_del</th>\n",
       "      <th>tempo_implementacao</th>\n",
       "      <th>num_std_sem_submissao</th>\n",
       "      <th>qtd_alteracoes_codigo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>72.625000</td>\n",
       "      <td>7.812500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>24.750000</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>820.450000</td>\n",
       "      <td>123.950000</td>\n",
       "      <td>88.009611</td>\n",
       "      <td>14.0</td>\n",
       "      <td>537.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>3.187500</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.187500</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>451.312500</td>\n",
       "      <td>57.625000</td>\n",
       "      <td>55.753800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>408.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>14.944444</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>310.388889</td>\n",
       "      <td>39.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>494.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>0.892857</td>\n",
       "      <td>5.517857</td>\n",
       "      <td>0.161812</td>\n",
       "      <td>22.732143</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>3.267857</td>\n",
       "      <td>955.035714</td>\n",
       "      <td>65.392857</td>\n",
       "      <td>164.854140</td>\n",
       "      <td>26.0</td>\n",
       "      <td>371.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>0.437500</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>15.312500</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2008.687500</td>\n",
       "      <td>116.187500</td>\n",
       "      <td>172.408286</td>\n",
       "      <td>13.0</td>\n",
       "      <td>793.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.609756</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>2.121951</td>\n",
       "      <td>3.731707</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>147.975610</td>\n",
       "      <td>12.902439</td>\n",
       "      <td>105.147439</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53.878049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>0.826087</td>\n",
       "      <td>9.304348</td>\n",
       "      <td>0.088785</td>\n",
       "      <td>20.521739</td>\n",
       "      <td>29.826087</td>\n",
       "      <td>8.478261</td>\n",
       "      <td>2.869565</td>\n",
       "      <td>5.608696</td>\n",
       "      <td>1505.260870</td>\n",
       "      <td>88.086957</td>\n",
       "      <td>57.915579</td>\n",
       "      <td>8.0</td>\n",
       "      <td>358.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>13.687500</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>1328.437500</td>\n",
       "      <td>64.625000</td>\n",
       "      <td>193.435200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>438.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>19.562500</td>\n",
       "      <td>21.812500</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2428.125000</td>\n",
       "      <td>118.250000</td>\n",
       "      <td>161.826154</td>\n",
       "      <td>14.0</td>\n",
       "      <td>498.062500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          taxa_acerto  num_submissoes  taxa_aceitacao  num_testes  \\\n",
       "question                                                            \n",
       "1002         1.000000        1.250000        0.800000    8.062500   \n",
       "1020         0.900000        6.750000        0.133333   18.000000   \n",
       "1023         0.937500        3.187500        0.294118   12.000000   \n",
       "1025         0.944444        1.777778        0.531250   13.166667   \n",
       "1027         0.892857        5.517857        0.161812   22.732143   \n",
       "...               ...             ...             ...         ...   \n",
       "3210         0.437500        3.437500        0.127273   15.312500   \n",
       "3229         1.000000        1.609756        0.621212    2.121951   \n",
       "3309         0.826087        9.304348        0.088785   20.521739   \n",
       "3583         0.625000        2.437500        0.256410   11.250000   \n",
       "3680         0.812500        2.250000        0.361111   19.562500   \n",
       "\n",
       "          num_consultas  num_erros  num_erros_lgcs  num_errors_stx  \\\n",
       "question                                                             \n",
       "1002           9.312500   0.250000        0.125000        0.125000   \n",
       "1020          24.750000   5.850000        1.350000        4.500000   \n",
       "1023          15.187500   2.250000        1.875000        0.375000   \n",
       "1025          14.944444   0.833333        0.444444        0.388889   \n",
       "1027          28.250000   4.625000        1.357143        3.267857   \n",
       "...                 ...        ...             ...             ...   \n",
       "3210          18.750000   3.000000        1.000000        2.000000   \n",
       "3229           3.731707   0.609756        0.121951        0.487805   \n",
       "3309          29.826087   8.478261        2.869565        5.608696   \n",
       "3583          13.687500   1.812500        0.375000        1.437500   \n",
       "3680          21.812500   1.437500        0.562500        0.875000   \n",
       "\n",
       "          num_eventos  num_eventos_del  tempo_implementacao  \\\n",
       "question                                                      \n",
       "1002        72.625000         7.812500             0.000000   \n",
       "1020       820.450000       123.950000            88.009611   \n",
       "1023       451.312500        57.625000            55.753800   \n",
       "1025       310.388889        39.055556             0.000000   \n",
       "1027       955.035714        65.392857           164.854140   \n",
       "...               ...              ...                  ...   \n",
       "3210      2008.687500       116.187500           172.408286   \n",
       "3229       147.975610        12.902439           105.147439   \n",
       "3309      1505.260870        88.086957            57.915579   \n",
       "3583      1328.437500        64.625000           193.435200   \n",
       "3680      2428.125000       118.250000           161.826154   \n",
       "\n",
       "          num_std_sem_submissao  qtd_alteracoes_codigo  \n",
       "question                                                \n",
       "1002                        2.0             151.750000  \n",
       "1020                       14.0             537.250000  \n",
       "1023                        2.0             408.187500  \n",
       "1025                        5.0             494.166667  \n",
       "1027                       26.0             371.750000  \n",
       "...                         ...                    ...  \n",
       "3210                       13.0             793.062500  \n",
       "3229                        7.0              53.878049  \n",
       "3309                        8.0             358.826087  \n",
       "3583                        5.0             438.562500  \n",
       "3680                       14.0             498.062500  \n",
       "\n",
       "[395 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dep_vars = pd.read_csv('./question_info.csv', index_col='question')\n",
    "dep_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab5e7d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador de questões\n",
    "def ternary_classify(rows, bounds, reverse=False):\n",
    "    if len(bounds) != 2:\n",
    "        raise Exception('quartiles must have 2 values, {} were given'.format(len(bounds)))\n",
    "        \n",
    "    values = ('facil', 'medio', 'dificil')\n",
    "    if reverse:\n",
    "        values = values[::-1]\n",
    "    return rows.apply(lambda row: \n",
    "                      values[0] if row <= bounds[0] else\n",
    "                      values[1] if row <= bounds[1] else\n",
    "                      values[2]\n",
    "                     )\n",
    "    \n",
    "def get_bounds_ternary(rows, column_name):\n",
    "    if column_name == 'taxa_acerto':\n",
    "        # Classificação do INEP\n",
    "        return (0.6, 0.85)\n",
    "    else:\n",
    "        return np.quantile(rows, q=[1/3, 2/3], interpolation='midpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f07ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador de questões\n",
    "def binary_classify(rows, bounds, reverse=False):\n",
    "    if len(bounds) != 1:\n",
    "        raise Exception('quartiles must have 1 values, {} were given'.format(len(bounds)))\n",
    "        \n",
    "    values = ('facil', 'dificil')\n",
    "    if reverse:\n",
    "        values = values[::-1]\n",
    "    return rows.apply(lambda row: \n",
    "                      values[0] if row <= bounds[0] else\n",
    "                      values[1]\n",
    "                     )\n",
    "    \n",
    "def get_bounds_binary(rows, column_name):\n",
    "    if column_name == 'taxa_acerto':\n",
    "        # Classificação do INEP\n",
    "        return (0.6,)\n",
    "    else:\n",
    "        return np.quantile(rows, q=[0.5], interpolation='midpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc6519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd8eabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxa_acerto</th>\n",
       "      <th>num_submissoes</th>\n",
       "      <th>taxa_aceitacao</th>\n",
       "      <th>num_testes</th>\n",
       "      <th>num_consultas</th>\n",
       "      <th>num_erros</th>\n",
       "      <th>num_erros_lgcs</th>\n",
       "      <th>num_errors_stx</th>\n",
       "      <th>num_eventos</th>\n",
       "      <th>num_eventos_del</th>\n",
       "      <th>tempo_implementacao</th>\n",
       "      <th>num_std_sem_submissao</th>\n",
       "      <th>qtd_alteracoes_codigo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>medio</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>medio</td>\n",
       "      <td>dificil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>medio</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>facil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>dificil</td>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>medio</td>\n",
       "      <td>medio</td>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "      <td>dificil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>medio</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "      <td>dificil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>medio</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>facil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>dificil</td>\n",
       "      <td>facil</td>\n",
       "      <td>medio</td>\n",
       "      <td>medio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         taxa_acerto num_submissoes taxa_aceitacao num_testes num_consultas  \\\n",
       "question                                                                      \n",
       "1002           facil          facil          facil      facil         facil   \n",
       "1020           facil        dificil          medio    dificil       dificil   \n",
       "1023           facil          facil          facil      facil         facil   \n",
       "1025           facil          facil          facil      medio         facil   \n",
       "1027           facil        dificil          medio    dificil       dificil   \n",
       "...              ...            ...            ...        ...           ...   \n",
       "3210         dificil          facil        dificil      medio         medio   \n",
       "3229           facil          facil          facil      facil         facil   \n",
       "3309           medio        dificil        dificil    dificil       dificil   \n",
       "3583           medio          facil          facil      facil         facil   \n",
       "3680           medio          facil          facil    dificil         medio   \n",
       "\n",
       "         num_erros num_erros_lgcs num_errors_stx num_eventos num_eventos_del  \\\n",
       "question                                                                       \n",
       "1002         facil          facil          facil       facil           facil   \n",
       "1020       dificil          facil        dificil       medio         dificil   \n",
       "1023         facil          medio          facil       facil           facil   \n",
       "1025         facil          facil          facil       facil           facil   \n",
       "1027         medio          facil        dificil     dificil           facil   \n",
       "...            ...            ...            ...         ...             ...   \n",
       "3210         medio          facil        dificil     dificil         dificil   \n",
       "3229         facil          facil          facil       facil           facil   \n",
       "3309       dificil        dificil        dificil     dificil           medio   \n",
       "3583         facil          facil          medio     dificil           facil   \n",
       "3680         facil          facil          facil     dificil         dificil   \n",
       "\n",
       "         tempo_implementacao num_std_sem_submissao qtd_alteracoes_codigo  \n",
       "question                                                                  \n",
       "1002                   facil                 facil                 facil  \n",
       "1020                   facil                 medio                 medio  \n",
       "1023                   facil                 facil                 medio  \n",
       "1025                   facil                 facil                 medio  \n",
       "1027                   facil               dificil                 facil  \n",
       "...                      ...                   ...                   ...  \n",
       "3210                   facil                 medio               dificil  \n",
       "3229                   facil                 facil                 facil  \n",
       "3309                   facil                 facil                 facil  \n",
       "3583                   medio                 facil                 medio  \n",
       "3680                   facil                 medio                 medio  \n",
       "\n",
       "[395 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified = pd.DataFrame(index=dep_vars.index, columns=dep_vars.columns)\n",
    "bounds = {}\n",
    "for col in classified:\n",
    "    bounds[col] = get_bounds_binary(dep_vars[col], col) if binary else get_bounds_ternary(dep_vars[col], col)\n",
    "    revert = col == 'taxa_acerto' or col == 'taxa_aceitacao'\n",
    "    classified[col] = binary_classify(dep_vars[col], bounds[col], revert) if binary \\\n",
    "        else ternary_classify(dep_vars[col], bounds[col], revert)\n",
    "classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74397c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medio      209\n",
       "facil      135\n",
       "dificil     51\n",
       "Name: taxa_acerto, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classified['taxa_acerto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1ce87d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f2209c3d880>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtick_labels = {'fácil': 'facil', 'difícil': 'dificil'} if binary else {'fácil': 'facil', 'médio': 'medio', 'difícil': 'dificil'}\n",
    "sns.catplot(data=classified, x='taxa_acerto', kind='count', edgecolor=\".3\", aspect=1.) \\\n",
    "    .set_xticklabels(xtick_labels) \\\n",
    "    .set_xlabels('Classificação') \\\n",
    "    .set_ylabels('Frequência')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0319a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'f1_micro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7421f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "classes = ['facil', 'dificil'] if binary else ['facil', 'medio', 'dificil']\n",
    "encoder.fit(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14920d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomendado não usar\n",
    "def basic_train(ind_vars, y, model, binary_class, is_encoded):\n",
    "    classes = ('facil', 'dificil') if binary_class else ('facil', 'medio', 'dificil')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(ind_vars, y, test_size=0.3, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if is_encoded:\n",
    "        y_test = encoder.inverse_transform(y_test)\n",
    "        y_pred = encoder.inverse_transform(y_pred)\n",
    "    \n",
    "    precision, recall, f1_macro, _ = precision_recall_fscore_support(y_pred, y_test, average='macro')\n",
    "    f1_micro = f1_score(y_pred, y_test, average='micro')\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "    }, cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e93f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_train(ind_vars, y, model, binary_class, is_encoded):\n",
    "    predicted_list = np.array([], dtype=int)\n",
    "    tested_list = np.array([], dtype=int)\n",
    "    kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, test_index in kf.split(ind_vars, y):\n",
    "        X_train, X_test = ind_vars.iloc[train_index], ind_vars.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Classe desbalanceada\n",
    "        if y.name == 'taxa_acerto':\n",
    "            oversample = SMOTE(random_state=42)\n",
    "            X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "   \n",
    "        tested_list = np.append(tested_list, y_test)\n",
    "        predicted_list = np.append(predicted_list, y_pred)\n",
    "        \n",
    "    if is_encoded:\n",
    "        tested_list = encoder.inverse_transform(tested_list)\n",
    "        predicted_list = encoder.inverse_transform(predicted_list)\n",
    "\n",
    "    classes = ('facil', 'dificil') if binary_class else ('facil', 'medio', 'dificil')\n",
    "    cnf_matrix = confusion_matrix(tested_list, predicted_list, labels=classes)\n",
    " \n",
    "    precision, recall, f1_macro, _ = precision_recall_fscore_support(tested_list, predicted_list, average='macro')\n",
    "    f1_micro = f1_score(tested_list, predicted_list, average='micro')\n",
    "    acc = accuracy_score(tested_list, predicted_list)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_macro': f1_macro,\n",
    "        'f1_micro': f1_micro,\n",
    "    }, cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddce97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(ind_vars, dep_vars, model, train_type = cross_val_train, binary_class = False, encode = False):\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1_macro', 'f1_micro']\n",
    "    results = pd.DataFrame(index=dep_vars.columns, columns=scoring)\n",
    "    cnf_matrixes = dict()\n",
    "    \n",
    "    for metric in results.index:\n",
    "        ndf = pd.Series(encoder.transform(dep_vars[metric]), name=metric, dtype=int) if encode else dep_vars[metric]\n",
    "        \n",
    "        metric_train_result, cnf_matrix = train_type(ind_vars, ndf, model, binary_class, is_encoded=encode)\n",
    "        results.loc[metric] = metric_train_result\n",
    "        cnf_matrixes[metric] = cnf_matrix\n",
    "\n",
    "    return results.sort_values(by=['f1_macro', 'f1_micro'], ascending=False), cnf_matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c0fef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train_search_cv(ind_vars, dep_vars, model, model_class, distributions, n_iter, train_type = cross_val_train, binary_class = False, encode = False):\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1_macro', 'f1_micro']\n",
    "    results = pd.DataFrame(index=dep_vars.columns, columns=scoring)\n",
    "    cnf_matrixes = dict()       \n",
    "    \n",
    "    for metric in results.index:\n",
    "        pipeline_ls = []\n",
    "        if metric == 'taxa_acerto':\n",
    "            pipeline_ls.append((\"smote\", SMOTE()))\n",
    "        pipeline_ls.append((\"model\", model))\n",
    "        \n",
    "        pipe_distributions = { f'model__{key}': value for key, value in distributions.items() }\n",
    "        pipeline = Pipeline(pipeline_ls)\n",
    "        \n",
    "        ndf = pd.Series(encoder.transform(dep_vars[metric]), name=metric, dtype=int) if encode else dep_vars[metric]\n",
    "        cross_val = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "        \n",
    "        clf = RandomizedSearchCV(\n",
    "            estimator=pipeline, \n",
    "            param_distributions=pipe_distributions, \n",
    "            random_state=42, \n",
    "            cv=cross_val, \n",
    "            n_iter=n_iter, \n",
    "            n_jobs=-1,\n",
    "            scoring='f1_micro',\n",
    "            return_train_score=True\n",
    "        )\n",
    "        search = clf.fit(ind_vars, ndf)\n",
    "        best_params = { key.split('__')[-1]: value for key, value in search.best_params_.items() }\n",
    "        print('best params for {}: {}'.format(metric, best_params))\n",
    "        best_model = model_class(**best_params)\n",
    "\n",
    "        metric_train_result, cnf_matrix = train_type(ind_vars, ndf, best_model, binary_class, is_encoded=encode)\n",
    "        results.loc[metric] = metric_train_result           \n",
    "        cnf_matrixes[metric] = cnf_matrix\n",
    "        \n",
    "    return results.sort_values(by=['f1_macro', 'f1_micro'], ascending=False), cnf_matrixes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e074246",
   "metadata": {},
   "source": [
    "## Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3433ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cnf_matrix, title, binary = True):\n",
    "    classes = ['fácil', 'difícil'] if binary else ['fácil', 'médio', 'difícil']\n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.style.use(style='default')\n",
    "    \n",
    "    plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.get_cmap('Blues'))\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cnf_matrix.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, format(cnf_matrix[i, j], fmt), horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Classe real')\n",
    "    plt.xlabel('Classe predita')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97c478b",
   "metadata": {},
   "source": [
    "## Experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93d6c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_best_results(best_results, df_results: pd.DataFrame, model):\n",
    "    for dep_var, metrics in df_results.iterrows():\n",
    "        acc_cur, f1_cur, _ = best_results[dep_var]\n",
    "        acc_nxt, f1_nxt = df_results.loc[dep_var, ['accuracy', 'f1_micro']]\n",
    "        if f1_nxt > f1_cur or (np.abs(f1_nxt - f1_cur) < 1e-6 and acc_nxt > acc_cur):\n",
    "            best_results[dep_var] = acc_nxt, f1_nxt, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df68523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dep_vars.columns\n",
    "best_results = dict()\n",
    "for col in columns:\n",
    "    best_results[col] = (0.0, 0.0, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c82b4c",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a662e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aae7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0411517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['rbf', 'poly']\n",
    "degree = [2, 3]\n",
    "C = np.arange(2, 1000)\n",
    "random_state = [42]\n",
    "distributions = dict(kernel=kernels, degree=degree, C=C, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ddb348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for taxa_acerto: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 808}\n",
      "best params for num_submissoes: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 808}\n",
      "best params for taxa_aceitacao: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 452}\n",
      "best params for num_testes: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 364}\n",
      "best params for num_consultas: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 869}\n",
      "best params for num_erros: {'random_state': 42, 'kernel': 'rbf', 'degree': 3, 'C': 319}\n",
      "best params for num_erros_lgcs: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 808}\n",
      "best params for num_errors_stx: {'random_state': 42, 'kernel': 'rbf', 'degree': 3, 'C': 574}\n",
      "best params for num_eventos: {'random_state': 42, 'kernel': 'poly', 'degree': 2, 'C': 799}\n",
      "best params for num_eventos_del: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 869}\n",
      "best params for tempo_implementacao: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 434}\n",
      "best params for num_std_sem_submissao: {'random_state': 42, 'kernel': 'rbf', 'degree': 2, 'C': 452}\n",
      "best params for qtd_alteracoes_codigo: {'random_state': 42, 'kernel': 'rbf', 'degree': 3, 'C': 296}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tempo_implementacao</th>\n",
       "      <td>0.602532</td>\n",
       "      <td>0.600847</td>\n",
       "      <td>0.602359</td>\n",
       "      <td>0.601373</td>\n",
       "      <td>0.602532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos_del</th>\n",
       "      <td>0.562025</td>\n",
       "      <td>0.567761</td>\n",
       "      <td>0.56157</td>\n",
       "      <td>0.559434</td>\n",
       "      <td>0.562025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qtd_alteracoes_codigo</th>\n",
       "      <td>0.559494</td>\n",
       "      <td>0.540412</td>\n",
       "      <td>0.558775</td>\n",
       "      <td>0.540072</td>\n",
       "      <td>0.559494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos</th>\n",
       "      <td>0.534177</td>\n",
       "      <td>0.564135</td>\n",
       "      <td>0.533676</td>\n",
       "      <td>0.512153</td>\n",
       "      <td>0.534177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_std_sem_submissao</th>\n",
       "      <td>0.488608</td>\n",
       "      <td>0.489603</td>\n",
       "      <td>0.491407</td>\n",
       "      <td>0.490404</td>\n",
       "      <td>0.488608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_testes</th>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.481213</td>\n",
       "      <td>0.480685</td>\n",
       "      <td>0.477846</td>\n",
       "      <td>0.481013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consultas</th>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.478704</td>\n",
       "      <td>0.478237</td>\n",
       "      <td>0.477621</td>\n",
       "      <td>0.478481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_acerto</th>\n",
       "      <td>0.463291</td>\n",
       "      <td>0.439676</td>\n",
       "      <td>0.494644</td>\n",
       "      <td>0.448458</td>\n",
       "      <td>0.463291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros_lgcs</th>\n",
       "      <td>0.44557</td>\n",
       "      <td>0.445122</td>\n",
       "      <td>0.444708</td>\n",
       "      <td>0.442886</td>\n",
       "      <td>0.44557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_aceitacao</th>\n",
       "      <td>0.432911</td>\n",
       "      <td>0.440171</td>\n",
       "      <td>0.432686</td>\n",
       "      <td>0.432893</td>\n",
       "      <td>0.432911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_submissoes</th>\n",
       "      <td>0.43038</td>\n",
       "      <td>0.433674</td>\n",
       "      <td>0.430392</td>\n",
       "      <td>0.431105</td>\n",
       "      <td>0.43038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_errors_stx</th>\n",
       "      <td>0.420253</td>\n",
       "      <td>0.424475</td>\n",
       "      <td>0.420194</td>\n",
       "      <td>0.418609</td>\n",
       "      <td>0.420253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros</th>\n",
       "      <td>0.410127</td>\n",
       "      <td>0.411604</td>\n",
       "      <td>0.409881</td>\n",
       "      <td>0.40952</td>\n",
       "      <td>0.410127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       accuracy precision    recall  f1_macro  f1_micro\n",
       "tempo_implementacao    0.602532  0.600847  0.602359  0.601373  0.602532\n",
       "num_eventos_del        0.562025  0.567761   0.56157  0.559434  0.562025\n",
       "qtd_alteracoes_codigo  0.559494  0.540412  0.558775  0.540072  0.559494\n",
       "num_eventos            0.534177  0.564135  0.533676  0.512153  0.534177\n",
       "num_std_sem_submissao  0.488608  0.489603  0.491407  0.490404  0.488608\n",
       "num_testes             0.481013  0.481213  0.480685  0.477846  0.481013\n",
       "num_consultas          0.478481  0.478704  0.478237  0.477621  0.478481\n",
       "taxa_acerto            0.463291  0.439676  0.494644  0.448458  0.463291\n",
       "num_erros_lgcs          0.44557  0.445122  0.444708  0.442886   0.44557\n",
       "taxa_aceitacao         0.432911  0.440171  0.432686  0.432893  0.432911\n",
       "num_submissoes          0.43038  0.433674  0.430392  0.431105   0.43038\n",
       "num_errors_stx         0.420253  0.424475  0.420194  0.418609  0.420253\n",
       "num_erros              0.410127  0.411604  0.409881   0.40952  0.410127"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, cnf_matrixes_svc = model_train_search_cv(ind_vars, classified, svc, SVC, distributions, 50, binary_class=binary)\n",
    "push_best_results(best_results, scores, 'SVM')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cnf_matrixes_svc['taxa_acerto'], title='', binary=binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b37ac5",
   "metadata": {},
   "source": [
    "### Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e130665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6765223",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "splitter = ['best', 'random']\n",
    "random_state = [42]\n",
    "distributions = dict(criterion=criterion, splitter=splitter, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cbd5e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for taxa_acerto: {'splitter': 'random', 'random_state': 42, 'criterion': 'gini'}\n",
      "best params for num_submissoes: {'splitter': 'best', 'random_state': 42, 'criterion': 'entropy'}\n",
      "best params for taxa_aceitacao: {'splitter': 'best', 'random_state': 42, 'criterion': 'entropy'}\n",
      "best params for num_testes: {'splitter': 'random', 'random_state': 42, 'criterion': 'log_loss'}\n",
      "best params for num_consultas: {'splitter': 'best', 'random_state': 42, 'criterion': 'entropy'}\n",
      "best params for num_erros: {'splitter': 'best', 'random_state': 42, 'criterion': 'entropy'}\n",
      "best params for num_erros_lgcs: {'splitter': 'random', 'random_state': 42, 'criterion': 'log_loss'}\n",
      "best params for num_errors_stx: {'splitter': 'random', 'random_state': 42, 'criterion': 'log_loss'}\n",
      "best params for num_eventos: {'splitter': 'random', 'random_state': 42, 'criterion': 'log_loss'}\n",
      "best params for num_eventos_del: {'splitter': 'best', 'random_state': 42, 'criterion': 'entropy'}\n",
      "best params for tempo_implementacao: {'splitter': 'random', 'random_state': 42, 'criterion': 'gini'}\n",
      "best params for num_std_sem_submissao: {'splitter': 'random', 'random_state': 42, 'criterion': 'gini'}\n",
      "best params for qtd_alteracoes_codigo: {'splitter': 'best', 'random_state': 42, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tempo_implementacao</th>\n",
       "      <td>0.587342</td>\n",
       "      <td>0.590444</td>\n",
       "      <td>0.587169</td>\n",
       "      <td>0.588225</td>\n",
       "      <td>0.587342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos</th>\n",
       "      <td>0.574684</td>\n",
       "      <td>0.577858</td>\n",
       "      <td>0.574447</td>\n",
       "      <td>0.575927</td>\n",
       "      <td>0.574684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos_del</th>\n",
       "      <td>0.572152</td>\n",
       "      <td>0.569157</td>\n",
       "      <td>0.571787</td>\n",
       "      <td>0.570001</td>\n",
       "      <td>0.572152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_acerto</th>\n",
       "      <td>0.564557</td>\n",
       "      <td>0.526669</td>\n",
       "      <td>0.55175</td>\n",
       "      <td>0.536322</td>\n",
       "      <td>0.564557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qtd_alteracoes_codigo</th>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.488591</td>\n",
       "      <td>0.493253</td>\n",
       "      <td>0.490569</td>\n",
       "      <td>0.493671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consultas</th>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.486519</td>\n",
       "      <td>0.490824</td>\n",
       "      <td>0.487675</td>\n",
       "      <td>0.491139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_testes</th>\n",
       "      <td>0.488608</td>\n",
       "      <td>0.481677</td>\n",
       "      <td>0.488241</td>\n",
       "      <td>0.483725</td>\n",
       "      <td>0.488608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros_lgcs</th>\n",
       "      <td>0.468354</td>\n",
       "      <td>0.466411</td>\n",
       "      <td>0.467765</td>\n",
       "      <td>0.466173</td>\n",
       "      <td>0.468354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_std_sem_submissao</th>\n",
       "      <td>0.437975</td>\n",
       "      <td>0.444952</td>\n",
       "      <td>0.440201</td>\n",
       "      <td>0.440575</td>\n",
       "      <td>0.437975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros</th>\n",
       "      <td>0.420253</td>\n",
       "      <td>0.418511</td>\n",
       "      <td>0.42004</td>\n",
       "      <td>0.418344</td>\n",
       "      <td>0.420253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_aceitacao</th>\n",
       "      <td>0.412658</td>\n",
       "      <td>0.416236</td>\n",
       "      <td>0.412387</td>\n",
       "      <td>0.41415</td>\n",
       "      <td>0.412658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_errors_stx</th>\n",
       "      <td>0.407595</td>\n",
       "      <td>0.406959</td>\n",
       "      <td>0.40751</td>\n",
       "      <td>0.407123</td>\n",
       "      <td>0.407595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_submissoes</th>\n",
       "      <td>0.402532</td>\n",
       "      <td>0.404112</td>\n",
       "      <td>0.402518</td>\n",
       "      <td>0.402864</td>\n",
       "      <td>0.402532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       accuracy precision    recall  f1_macro  f1_micro\n",
       "tempo_implementacao    0.587342  0.590444  0.587169  0.588225  0.587342\n",
       "num_eventos            0.574684  0.577858  0.574447  0.575927  0.574684\n",
       "num_eventos_del        0.572152  0.569157  0.571787  0.570001  0.572152\n",
       "taxa_acerto            0.564557  0.526669   0.55175  0.536322  0.564557\n",
       "qtd_alteracoes_codigo  0.493671  0.488591  0.493253  0.490569  0.493671\n",
       "num_consultas          0.491139  0.486519  0.490824  0.487675  0.491139\n",
       "num_testes             0.488608  0.481677  0.488241  0.483725  0.488608\n",
       "num_erros_lgcs         0.468354  0.466411  0.467765  0.466173  0.468354\n",
       "num_std_sem_submissao  0.437975  0.444952  0.440201  0.440575  0.437975\n",
       "num_erros              0.420253  0.418511   0.42004  0.418344  0.420253\n",
       "taxa_aceitacao         0.412658  0.416236  0.412387   0.41415  0.412658\n",
       "num_errors_stx         0.407595  0.406959   0.40751  0.407123  0.407595\n",
       "num_submissoes         0.402532  0.404112  0.402518  0.402864  0.402532"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "scores, cnf_matrixes_dt = model_train_search_cv(ind_vars, classified, tree, DecisionTreeClassifier, distributions, 4, binary_class=binary)\n",
    "push_best_results(best_results, scores, 'Árvore de Decisão')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07e7d6c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6689800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96cf6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = np.linspace(start=100, stop=1000, num=10, dtype=int)\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "class_weight = ['balanced', 'balanced_subsample', None]\n",
    "random_state = [42]\n",
    "distributions = dict(\n",
    "    n_estimators=n_estimators,\n",
    "    criterion=criterion,\n",
    "    class_weight=class_weight,\n",
    "    random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feb8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators=10, criterion='entropy', class_weight='balanced', random_state=42)\n",
    "# scores, cnf_matrixes = model_train(ind_vars, classified, model, train_type = cross_val_train, binary_class=binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42d43ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for taxa_acerto: {'random_state': 42, 'n_estimators': 200, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "best params for num_submissoes: {'random_state': 42, 'n_estimators': 1000, 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}\n",
      "best params for taxa_aceitacao: {'random_state': 42, 'n_estimators': 200, 'criterion': 'log_loss', 'class_weight': None}\n",
      "best params for num_testes: {'random_state': 42, 'n_estimators': 400, 'criterion': 'gini', 'class_weight': 'balanced'}\n",
      "best params for num_consultas: {'random_state': 42, 'n_estimators': 100, 'criterion': 'entropy', 'class_weight': None}\n",
      "best params for num_erros: {'random_state': 42, 'n_estimators': 900, 'criterion': 'entropy', 'class_weight': None}\n",
      "best params for num_erros_lgcs: {'random_state': 42, 'n_estimators': 600, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample'}\n",
      "best params for num_errors_stx: {'random_state': 42, 'n_estimators': 100, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "best params for num_eventos: {'random_state': 42, 'n_estimators': 100, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "best params for num_eventos_del: {'random_state': 42, 'n_estimators': 100, 'criterion': 'gini', 'class_weight': 'balanced'}\n",
      "best params for tempo_implementacao: {'random_state': 42, 'n_estimators': 100, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "best params for num_std_sem_submissao: {'random_state': 42, 'n_estimators': 600, 'criterion': 'gini', 'class_weight': None}\n",
      "best params for qtd_alteracoes_codigo: {'random_state': 42, 'n_estimators': 500, 'criterion': 'log_loss', 'class_weight': 'balanced'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tempo_implementacao</th>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.658518</td>\n",
       "      <td>0.657896</td>\n",
       "      <td>0.658025</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos</th>\n",
       "      <td>0.612658</td>\n",
       "      <td>0.610612</td>\n",
       "      <td>0.612287</td>\n",
       "      <td>0.610248</td>\n",
       "      <td>0.612658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos_del</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.593146</td>\n",
       "      <td>0.599526</td>\n",
       "      <td>0.595436</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qtd_alteracoes_codigo</th>\n",
       "      <td>0.602532</td>\n",
       "      <td>0.588241</td>\n",
       "      <td>0.601897</td>\n",
       "      <td>0.589645</td>\n",
       "      <td>0.602532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_testes</th>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.544646</td>\n",
       "      <td>0.544105</td>\n",
       "      <td>0.544336</td>\n",
       "      <td>0.544304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consultas</th>\n",
       "      <td>0.539241</td>\n",
       "      <td>0.537681</td>\n",
       "      <td>0.538939</td>\n",
       "      <td>0.538116</td>\n",
       "      <td>0.539241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_acerto</th>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.529078</td>\n",
       "      <td>0.518445</td>\n",
       "      <td>0.522881</td>\n",
       "      <td>0.582278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_std_sem_submissao</th>\n",
       "      <td>0.501266</td>\n",
       "      <td>0.508586</td>\n",
       "      <td>0.504515</td>\n",
       "      <td>0.506331</td>\n",
       "      <td>0.501266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros_lgcs</th>\n",
       "      <td>0.483544</td>\n",
       "      <td>0.474297</td>\n",
       "      <td>0.482452</td>\n",
       "      <td>0.477108</td>\n",
       "      <td>0.483544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_submissoes</th>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.470186</td>\n",
       "      <td>0.473475</td>\n",
       "      <td>0.471325</td>\n",
       "      <td>0.473418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros</th>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.469755</td>\n",
       "      <td>0.47307</td>\n",
       "      <td>0.470984</td>\n",
       "      <td>0.473418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_errors_stx</th>\n",
       "      <td>0.463291</td>\n",
       "      <td>0.462735</td>\n",
       "      <td>0.463201</td>\n",
       "      <td>0.46232</td>\n",
       "      <td>0.463291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_aceitacao</th>\n",
       "      <td>0.435443</td>\n",
       "      <td>0.435069</td>\n",
       "      <td>0.435076</td>\n",
       "      <td>0.432951</td>\n",
       "      <td>0.435443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       accuracy precision    recall  f1_macro  f1_micro\n",
       "tempo_implementacao    0.658228  0.658518  0.657896  0.658025  0.658228\n",
       "num_eventos            0.612658  0.610612  0.612287  0.610248  0.612658\n",
       "num_eventos_del             0.6  0.593146  0.599526  0.595436       0.6\n",
       "qtd_alteracoes_codigo  0.602532  0.588241  0.601897  0.589645  0.602532\n",
       "num_testes             0.544304  0.544646  0.544105  0.544336  0.544304\n",
       "num_consultas          0.539241  0.537681  0.538939  0.538116  0.539241\n",
       "taxa_acerto            0.582278  0.529078  0.518445  0.522881  0.582278\n",
       "num_std_sem_submissao  0.501266  0.508586  0.504515  0.506331  0.501266\n",
       "num_erros_lgcs         0.483544  0.474297  0.482452  0.477108  0.483544\n",
       "num_submissoes         0.473418  0.470186  0.473475  0.471325  0.473418\n",
       "num_erros              0.473418  0.469755   0.47307  0.470984  0.473418\n",
       "num_errors_stx         0.463291  0.462735  0.463201   0.46232  0.463291\n",
       "taxa_aceitacao         0.435443  0.435069  0.435076  0.432951  0.435443"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_forest = RandomForestClassifier()\n",
    "scores, cnf_matrixes_rf = model_train_search_cv(ind_vars, classified, rd_forest, RandomForestClassifier, distributions, 50, binary_class=binary)\n",
    "push_best_results(best_results, scores, 'Random Forest')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afacccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cnf_matrixes_rf['taxa_acerto'], '', binary=binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867f465",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec37e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6dc4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gboost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d5e9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ['log_loss', 'exponential']\n",
    "learning_rate = np.linspace(start=0.01, stop=0.5, num=10)\n",
    "n_estimators = np.linspace(start=1, stop=500, num=10, dtype=int)\n",
    "criterion = ['friedman_mse', 'squared_error']\n",
    "random_state = [42]\n",
    "\n",
    "distributions = dict(\n",
    "    loss = loss,\n",
    "    learning_rate = learning_rate,\n",
    "    n_estimators = n_estimators,\n",
    "    criterion = criterion,\n",
    "    random_state=random_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0bb961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GradientBoostingClassifier(loss='deviance', learning_rate=0.01, n_estimators=1000, criterion='mse')\n",
    "# scores, cnf_matrixes = model_train(ind_vars, classified, model)\n",
    "# push_best_results(best_results, scores, 'Gradient Boosting')\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b220c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.60263348 0.50891569        nan        nan        nan 0.54174397\n",
      " 0.55444754        nan 0.5721243  0.56207483]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.90970516 0.65735906        nan        nan        nan 0.98396977\n",
      " 0.98396977        nan 0.98396977 0.98396977]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for taxa_acerto: {'random_state': 42, 'n_estimators': 500, 'loss': 'log_loss', 'learning_rate': 0.01, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.43820862 0.42537621        nan        nan        nan 0.42547928\n",
      " 0.4153525         nan 0.40262317 0.42292826]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.88102876 0.59495291        nan        nan        nan 0.95274252\n",
      " 0.95274252        nan 0.95274252 0.95274252]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_submissoes: {'random_state': 42, 'n_estimators': 500, 'loss': 'log_loss', 'learning_rate': 0.01, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.42769532 0.37224284        nan        nan        nan 0.43027211\n",
      " 0.4251443         nan 0.4251443  0.42001649]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.88185344 0.6126638         nan        nan        nan 0.96286628\n",
      " 0.96286628        nan 0.96286628 0.96286628]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for taxa_aceitacao: {'random_state': 42, 'n_estimators': 222, 'loss': 'log_loss', 'learning_rate': 0.22777777777777777, 'criterion': 'friedman_mse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.51904247 0.46575448        nan        nan        nan 0.51144094\n",
      " 0.50376211        nan 0.51651721 0.50628736]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.89367777 0.61856743        nan        nan        nan 0.96287765\n",
      " 0.96287765        nan 0.96287765 0.96287765]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_testes: {'random_state': 42, 'n_estimators': 500, 'loss': 'log_loss', 'learning_rate': 0.01, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.48600804 0.40762214        nan        nan        nan 0.4859565\n",
      " 0.49613482        nan 0.48085446 0.50621006]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.89365786 0.58733449        nan        nan        nan 0.95949927\n",
      " 0.95949927        nan 0.95949927 0.95949927]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_consultas: {'random_state': 42, 'n_estimators': 333, 'loss': 'log_loss', 'learning_rate': 0.33666666666666667, 'criterion': 'friedman_mse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.44544939 0.40012369        nan        nan        nan 0.44800041\n",
      " 0.4505772         nan 0.46567718 0.44802618]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.88860167 0.59744972        nan        nan        nan 0.95696264\n",
      " 0.95696264        nan 0.95696264 0.95696264]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_erros: {'random_state': 42, 'n_estimators': 333, 'loss': 'log_loss', 'learning_rate': 0.17333333333333334, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.48623995 0.43287467        nan        nan        nan 0.50636467\n",
      " 0.50881262        nan 0.4886879  0.51144094]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.88268951 0.62105287        nan        nan        nan 0.95611236\n",
      " 0.95611236        nan 0.95611236 0.95611236]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_erros_lgcs: {'random_state': 42, 'n_estimators': 333, 'loss': 'log_loss', 'learning_rate': 0.33666666666666667, 'criterion': 'friedman_mse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.46583179 0.42774686        nan        nan        nan 0.46827974\n",
      " 0.49108431        nan 0.45567924 0.4809833 ]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.87510238 0.60000057        nan        nan        nan 0.95610952\n",
      " 0.95610952        nan 0.95610952 0.95610952]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_errors_stx: {'random_state': 42, 'n_estimators': 500, 'loss': 'log_loss', 'learning_rate': 0.33666666666666667, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.59227479 0.57464956        nan        nan        nan 0.57707174\n",
      " 0.59498042        nan 0.58467326 0.58477633]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.9054765  0.69958595        nan        nan        nan 0.96878413\n",
      " 0.96878413        nan 0.96878413 0.96878413]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_eventos: {'random_state': 42, 'n_estimators': 500, 'loss': 'log_loss', 'learning_rate': 0.33666666666666667, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.59230056 0.4886879         nan        nan        nan 0.57720058\n",
      " 0.55954958        nan 0.59495465 0.55952381]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.91476988 0.69199313        nan        nan        nan 0.97046194\n",
      " 0.97046194        nan 0.97046194 0.97046194]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_eventos_del: {'random_state': 42, 'n_estimators': 333, 'loss': 'log_loss', 'learning_rate': 0.17333333333333334, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.65824057 0.62778293        nan        nan        nan 0.61775922\n",
      " 0.6405638         nan 0.62028448 0.63298804]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.92319308 0.71392131        nan        nan        nan 0.97130369\n",
      " 0.97130369        nan 0.97130369 0.97130369]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for tempo_implementacao: {'random_state': 42, 'n_estimators': 500, 'loss': 'log_loss', 'learning_rate': 0.01, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.48353432 0.39991754        nan        nan        nan 0.47083076\n",
      " 0.49111008        nan 0.49360957 0.49616059]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.87847507 0.59499556        nan        nan        nan 0.96034102\n",
      " 0.96034102        nan 0.96034102 0.96034102]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for num_std_sem_submissao: {'random_state': 42, 'n_estimators': 333, 'loss': 'log_loss', 'learning_rate': 0.33666666666666667, 'criterion': 'friedman_mse'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "16 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 272, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 577, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 331, in _check_params\n",
      "    self._loss = loss_class(self.n_classes_)\n",
      "  File \"/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.59997939 0.54939703        nan        nan        nan 0.59495465\n",
      " 0.60505566        nan 0.60500412 0.58730159]\n",
      "  warnings.warn(\n",
      "/home/jackson/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.89620871 0.72573994        nan        nan        nan 0.96540575\n",
      " 0.96540575        nan 0.96540575 0.96540575]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for qtd_alteracoes_codigo: {'random_state': 42, 'n_estimators': 500, 'loss': 'log_loss', 'learning_rate': 0.33666666666666667, 'criterion': 'squared_error'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tempo_implementacao</th>\n",
       "      <td>0.663291</td>\n",
       "      <td>0.666585</td>\n",
       "      <td>0.663004</td>\n",
       "      <td>0.664588</td>\n",
       "      <td>0.663291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos</th>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.614782</td>\n",
       "      <td>0.607371</td>\n",
       "      <td>0.609629</td>\n",
       "      <td>0.607595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos_del</th>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.600712</td>\n",
       "      <td>0.594745</td>\n",
       "      <td>0.597141</td>\n",
       "      <td>0.594937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qtd_alteracoes_codigo</th>\n",
       "      <td>0.539241</td>\n",
       "      <td>0.533691</td>\n",
       "      <td>0.538804</td>\n",
       "      <td>0.535906</td>\n",
       "      <td>0.539241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_testes</th>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.532364</td>\n",
       "      <td>0.528877</td>\n",
       "      <td>0.530162</td>\n",
       "      <td>0.529114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consultas</th>\n",
       "      <td>0.529114</td>\n",
       "      <td>0.531654</td>\n",
       "      <td>0.528838</td>\n",
       "      <td>0.530039</td>\n",
       "      <td>0.529114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_acerto</th>\n",
       "      <td>0.56962</td>\n",
       "      <td>0.514303</td>\n",
       "      <td>0.506973</td>\n",
       "      <td>0.510195</td>\n",
       "      <td>0.56962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros_lgcs</th>\n",
       "      <td>0.501266</td>\n",
       "      <td>0.495404</td>\n",
       "      <td>0.500324</td>\n",
       "      <td>0.496919</td>\n",
       "      <td>0.501266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_submissoes</th>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.480426</td>\n",
       "      <td>0.478526</td>\n",
       "      <td>0.479316</td>\n",
       "      <td>0.478481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_errors_stx</th>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.480182</td>\n",
       "      <td>0.478487</td>\n",
       "      <td>0.478692</td>\n",
       "      <td>0.478481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_std_sem_submissao</th>\n",
       "      <td>0.465823</td>\n",
       "      <td>0.468553</td>\n",
       "      <td>0.469376</td>\n",
       "      <td>0.46883</td>\n",
       "      <td>0.465823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros</th>\n",
       "      <td>0.448101</td>\n",
       "      <td>0.450091</td>\n",
       "      <td>0.447914</td>\n",
       "      <td>0.448894</td>\n",
       "      <td>0.448101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_aceitacao</th>\n",
       "      <td>0.407595</td>\n",
       "      <td>0.412322</td>\n",
       "      <td>0.407317</td>\n",
       "      <td>0.408888</td>\n",
       "      <td>0.407595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       accuracy precision    recall  f1_macro  f1_micro\n",
       "tempo_implementacao    0.663291  0.666585  0.663004  0.664588  0.663291\n",
       "num_eventos            0.607595  0.614782  0.607371  0.609629  0.607595\n",
       "num_eventos_del        0.594937  0.600712  0.594745  0.597141  0.594937\n",
       "qtd_alteracoes_codigo  0.539241  0.533691  0.538804  0.535906  0.539241\n",
       "num_testes             0.529114  0.532364  0.528877  0.530162  0.529114\n",
       "num_consultas          0.529114  0.531654  0.528838  0.530039  0.529114\n",
       "taxa_acerto             0.56962  0.514303  0.506973  0.510195   0.56962\n",
       "num_erros_lgcs         0.501266  0.495404  0.500324  0.496919  0.501266\n",
       "num_submissoes         0.478481  0.480426  0.478526  0.479316  0.478481\n",
       "num_errors_stx         0.478481  0.480182  0.478487  0.478692  0.478481\n",
       "num_std_sem_submissao  0.465823  0.468553  0.469376   0.46883  0.465823\n",
       "num_erros              0.448101  0.450091  0.447914  0.448894  0.448101\n",
       "taxa_aceitacao         0.407595  0.412322  0.407317  0.408888  0.407595"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, cnf_matrixes_gb = model_train_search_cv(ind_vars, classified, model=gboost, model_class=GradientBoostingClassifier, distributions=distributions, n_iter=10, binary_class=binary)\n",
    "push_best_results(best_results, scores, 'Gradient Boosting')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270837c",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1360475",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0d0bfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': array([100, 144, 188, 233, 277, 322, 366, 411, 455, 500]),\n",
       " 'max_depth': array([ 3,  3,  4,  5,  6,  7,  8,  9,  9, 10, 11, 12, 13, 14, 15]),\n",
       " 'eta': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
       " 'subsample': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ], dtype=float32),\n",
       " 'random_state': [42]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = np.linspace(start=100, stop=500, num=10, dtype=int)\n",
    "max_depth = np.linspace(start=3, stop=15, num=15, dtype=int)\n",
    "eta = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "subsample = np.linspace(start=0.1, stop=1.0, num=10, dtype=np.float32)\n",
    "random_state = [42]\n",
    "\n",
    "distributions = dict(n_estimators=n_estimators, max_depth=max_depth, eta=eta, subsample=subsample, random_state=random_state)\n",
    "distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c99b4f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for taxa_acerto: {'subsample': 1.0, 'random_state': 42, 'n_estimators': 366, 'max_depth': 9, 'eta': 0.0001}\n",
      "best params for num_submissoes: {'subsample': 0.5, 'random_state': 42, 'n_estimators': 411, 'max_depth': 6, 'eta': 0.0001}\n",
      "best params for taxa_aceitacao: {'subsample': 0.7, 'random_state': 42, 'n_estimators': 188, 'max_depth': 9, 'eta': 0.1}\n",
      "best params for num_testes: {'subsample': 0.5, 'random_state': 42, 'n_estimators': 277, 'max_depth': 6, 'eta': 0.01}\n",
      "best params for num_consultas: {'subsample': 0.2, 'random_state': 42, 'n_estimators': 411, 'max_depth': 3, 'eta': 0.01}\n",
      "best params for num_erros: {'subsample': 0.2, 'random_state': 42, 'n_estimators': 144, 'max_depth': 12, 'eta': 0.1}\n",
      "best params for num_erros_lgcs: {'subsample': 0.1, 'random_state': 42, 'n_estimators': 500, 'max_depth': 9, 'eta': 0.1}\n",
      "best params for num_errors_stx: {'subsample': 0.2, 'random_state': 42, 'n_estimators': 322, 'max_depth': 7, 'eta': 0.1}\n",
      "best params for num_eventos: {'subsample': 0.5, 'random_state': 42, 'n_estimators': 233, 'max_depth': 9, 'eta': 0.1}\n",
      "best params for num_eventos_del: {'subsample': 0.3, 'random_state': 42, 'n_estimators': 500, 'max_depth': 3, 'eta': 0.01}\n",
      "best params for tempo_implementacao: {'subsample': 0.7, 'random_state': 42, 'n_estimators': 100, 'max_depth': 5, 'eta': 0.001}\n",
      "best params for num_std_sem_submissao: {'subsample': 0.2, 'random_state': 42, 'n_estimators': 411, 'max_depth': 3, 'eta': 0.01}\n",
      "best params for qtd_alteracoes_codigo: {'subsample': 0.6, 'random_state': 42, 'n_estimators': 455, 'max_depth': 5, 'eta': 0.01}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tempo_implementacao</th>\n",
       "      <td>0.668354</td>\n",
       "      <td>0.671156</td>\n",
       "      <td>0.668074</td>\n",
       "      <td>0.669459</td>\n",
       "      <td>0.668354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos_del</th>\n",
       "      <td>0.605063</td>\n",
       "      <td>0.600632</td>\n",
       "      <td>0.604596</td>\n",
       "      <td>0.60147</td>\n",
       "      <td>0.605063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos</th>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.60014</td>\n",
       "      <td>0.597174</td>\n",
       "      <td>0.597527</td>\n",
       "      <td>0.597468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qtd_alteracoes_codigo</th>\n",
       "      <td>0.602532</td>\n",
       "      <td>0.592707</td>\n",
       "      <td>0.602012</td>\n",
       "      <td>0.595412</td>\n",
       "      <td>0.602532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_testes</th>\n",
       "      <td>0.536709</td>\n",
       "      <td>0.538425</td>\n",
       "      <td>0.53651</td>\n",
       "      <td>0.537245</td>\n",
       "      <td>0.536709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consultas</th>\n",
       "      <td>0.516456</td>\n",
       "      <td>0.515296</td>\n",
       "      <td>0.516077</td>\n",
       "      <td>0.514393</td>\n",
       "      <td>0.516456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_std_sem_submissao</th>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.499169</td>\n",
       "      <td>0.493913</td>\n",
       "      <td>0.49602</td>\n",
       "      <td>0.491139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros_lgcs</th>\n",
       "      <td>0.498734</td>\n",
       "      <td>0.492794</td>\n",
       "      <td>0.497952</td>\n",
       "      <td>0.494272</td>\n",
       "      <td>0.498734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_submissoes</th>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.489586</td>\n",
       "      <td>0.491287</td>\n",
       "      <td>0.490314</td>\n",
       "      <td>0.491139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_acerto</th>\n",
       "      <td>0.536709</td>\n",
       "      <td>0.478675</td>\n",
       "      <td>0.475179</td>\n",
       "      <td>0.47505</td>\n",
       "      <td>0.536709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_aceitacao</th>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.473546</td>\n",
       "      <td>0.473128</td>\n",
       "      <td>0.472701</td>\n",
       "      <td>0.473418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros</th>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.469717</td>\n",
       "      <td>0.47307</td>\n",
       "      <td>0.471094</td>\n",
       "      <td>0.473418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_errors_stx</th>\n",
       "      <td>0.460759</td>\n",
       "      <td>0.461141</td>\n",
       "      <td>0.460714</td>\n",
       "      <td>0.460758</td>\n",
       "      <td>0.460759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       accuracy precision    recall  f1_macro  f1_micro\n",
       "tempo_implementacao    0.668354  0.671156  0.668074  0.669459  0.668354\n",
       "num_eventos_del        0.605063  0.600632  0.604596   0.60147  0.605063\n",
       "num_eventos            0.597468   0.60014  0.597174  0.597527  0.597468\n",
       "qtd_alteracoes_codigo  0.602532  0.592707  0.602012  0.595412  0.602532\n",
       "num_testes             0.536709  0.538425   0.53651  0.537245  0.536709\n",
       "num_consultas          0.516456  0.515296  0.516077  0.514393  0.516456\n",
       "num_std_sem_submissao  0.491139  0.499169  0.493913   0.49602  0.491139\n",
       "num_erros_lgcs         0.498734  0.492794  0.497952  0.494272  0.498734\n",
       "num_submissoes         0.491139  0.489586  0.491287  0.490314  0.491139\n",
       "taxa_acerto            0.536709  0.478675  0.475179   0.47505  0.536709\n",
       "taxa_aceitacao         0.473418  0.473546  0.473128  0.472701  0.473418\n",
       "num_erros              0.473418  0.469717   0.47307  0.471094  0.473418\n",
       "num_errors_stx         0.460759  0.461141  0.460714  0.460758  0.460759"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, cnf_matrixes_xgb = model_train_search_cv(ind_vars, classified, model=xgb, model_class=XGBClassifier, distributions=distributions, n_iter=50, binary_class=binary, encode=True)\n",
    "push_best_results(best_results, scores, 'Extreme Gradient Boosting')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4ffc5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tempo_implementacao</th>\n",
       "      <td>0.668354</td>\n",
       "      <td>0.668354</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos</th>\n",
       "      <td>0.612658</td>\n",
       "      <td>0.612658</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_eventos_del</th>\n",
       "      <td>0.605063</td>\n",
       "      <td>0.605063</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qtd_alteracoes_codigo</th>\n",
       "      <td>0.602532</td>\n",
       "      <td>0.602532</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_acerto</th>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_testes</th>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_consultas</th>\n",
       "      <td>0.539241</td>\n",
       "      <td>0.539241</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros_lgcs</th>\n",
       "      <td>0.501266</td>\n",
       "      <td>0.501266</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_std_sem_submissao</th>\n",
       "      <td>0.501266</td>\n",
       "      <td>0.501266</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_submissoes</th>\n",
       "      <td>0.491139</td>\n",
       "      <td>0.491139</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_errors_stx</th>\n",
       "      <td>0.478481</td>\n",
       "      <td>0.478481</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxa_aceitacao</th>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.473418</td>\n",
       "      <td>Extreme Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_erros</th>\n",
       "      <td>0.473418</td>\n",
       "      <td>0.473418</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       f1_micro  accuracy              classificador\n",
       "tempo_implementacao    0.668354  0.668354  Extreme Gradient Boosting\n",
       "num_eventos            0.612658  0.612658              Random Forest\n",
       "num_eventos_del        0.605063  0.605063  Extreme Gradient Boosting\n",
       "qtd_alteracoes_codigo  0.602532  0.602532              Random Forest\n",
       "taxa_acerto            0.582278  0.582278              Random Forest\n",
       "num_testes             0.544304  0.544304              Random Forest\n",
       "num_consultas          0.539241  0.539241              Random Forest\n",
       "num_erros_lgcs         0.501266  0.501266          Gradient Boosting\n",
       "num_std_sem_submissao  0.501266  0.501266              Random Forest\n",
       "num_submissoes         0.491139  0.491139  Extreme Gradient Boosting\n",
       "num_errors_stx         0.478481  0.478481          Gradient Boosting\n",
       "taxa_aceitacao         0.473418  0.473418  Extreme Gradient Boosting\n",
       "num_erros              0.473418  0.473418              Random Forest"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_df = pd.DataFrame(best_results, index=['f1_micro', 'accuracy', 'classificador']) \\\n",
    "    .T.sort_values(by=['f1_micro', 'accuracy'], ascending=False)\n",
    "best_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_df.to_csv('results_classification_3n_microavg2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8b4fa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrixes_rf['taxa_acerto'], '', binary=binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b960a5",
   "metadata": {},
   "source": [
    "## Reduzindo número de variáveis independentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b39f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_code_metrics = pd.read_csv('./best_code_metrics.csv', index_col='metric')\n",
    "code_attrs = pd.DataFrame(index=best_code_metrics.index, columns=best_code_metrics.columns)\n",
    "for row in best_code_metrics.iterrows():\n",
    "    cols = row[1].apply(lambda item: eval(item)[1])\n",
    "    code_attrs.loc[row[0],:] = cols\n",
    "code_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74030865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_search_cv(ind_vars, classified, svc, SVC, distributions, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaaf3b7",
   "metadata": {},
   "source": [
    "## Selecionando métricas mais comuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6084df",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = {}\n",
    "for row in code_attrs.iterrows():\n",
    "    for key in row[1]:\n",
    "        if not key in attrs:\n",
    "            attrs[key] = 0\n",
    "        attrs[key] += 1\n",
    "best_attrs = list(attrs.items())\n",
    "best_attrs.sort(key=lambda key: key[1], reverse=True)\n",
    "best_attrs = list(map(lambda x: x[0], best_attrs[:10]))\n",
    "best_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15643beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_classified = ind_vars[best_attrs] \n",
    "filtered_classified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
